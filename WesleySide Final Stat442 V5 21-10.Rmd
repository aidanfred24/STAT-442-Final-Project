---
title: "Wesley Side Final Stat442"
author: "Wesley Nelson"
date: "`r Sys.Date()`"
output: html_document
---

```{r Packages, message=FALSE, warning=FALSE}

library(dplyr)
library(readr)
library(DataExplorer)
library(cluster)
library(factoextra)
library(FactoMineR)

knitr::opts_chunk$set(echo = TRUE)
```





```{r Data/Cleaning, warning=FALSE}

toxins_2023 <- read_csv("C:/Users/wanel/OneDrive/Documents/GitHub/STAT-442-Final-Project/Datasets/2023_us.csv")


toxins_clean <- toxins_2023 %>%
  select(-c(24:29)) %>%
  mutate(`45. METAL CATEGORY` = ifelse(`45. METAL CATEGORY` == "Metal complound categories", "Metal compound categories",`45. METAL CATEGORY` )) 
View(toxins_clean)
  




```

```{r Clustering}

# Data preparation for on-site
toxins_clustered_on_site <- toxins_2023 %>%
  select(c(51:53, 55, 56, 58:60, 62:65)) %>%
  na.omit()

# Scaling the data
toxins_clustered_on_site_scaled <- scale(toxins_clustered_on_site)

# Data preparation for off-site
toxins_clustered_off_site <- toxins_2023 %>%
  select(c(66:71, 75, 76, 79:88)) %>%
  na.omit()

# Scaling the data
toxins_clustered_off_site_scaled <- scale(toxins_clustered_off_site)

sample_size <- 10000

# For on-site data
random_sample_on_site <- toxins_clustered_on_site_scaled[sample(1:nrow(toxins_clustered_on_site_scaled), sample_size), ]

# For off-site data
random_sample_off_site <- toxins_clustered_off_site_scaled[sample(1:nrow(toxins_clustered_off_site_scaled), sample_size), ]

# Step 2: Visualize the elbow method using fviz_nbclust (within-cluster sum of squares)
# On-site data
fviz_nbclust(random_sample_on_site, kmeans, method = "silhouette") +
  ggtitle("Silhouette Method for On-site Data")

# Off-site data
fviz_nbclust(random_sample_off_site, kmeans, method = "silhouette") +
  ggtitle("Silhouette Method for Off-site Data")



# Clustering with 2 clusters for on-site
kmeans_on_site <- kmeans(toxins_clustered_on_site_scaled, centers = 2)
kmeans_on_site$centers
kmeans_on_site$size
kmeans_on_site$tot.withinss

# Display the ratio of between_SS to total_SS
between_tot_ratio_on <- kmeans_on_site$betweenss / kmeans_on_site$totss * 100
cat("Between_SS / Total_SS =", round(between_tot_ratio_on, 1), "%\n")


fviz_cluster(kmeans_on_site, data = toxins_clustered_on_site_scaled, 
             geom = "point", ellipse.type = "norm", 
             ggtheme = theme_minimal())

# Clustering with 6 clusters for off-site
kmeans_off_site <- kmeans(toxins_clustered_off_site_scaled, centers = 2)
kmeans_off_site$centers
kmeans_off_site$size
kmeans_off_site$tot.withinss

# Display the ratio of between_SS to total_SS
between_tot_ratio_off <- kmeans_off_site$betweenss / kmeans_off_site$totss * 100
cat("Between_SS / Total_SS =", round(between_tot_ratio_off, 1), "%\n")

fviz_cluster(kmeans_off_site, data = toxins_clustered_off_site_scaled, 
             geom = "point", ellipse.type = "norm", 
             ggtheme = theme_minimal())

# Data preparation for total
toxins_clustered_total <- toxins_2023 %>%
  select(c(65, 88, 94, 113, 116, 119, 107, 106, 120)) %>%
  na.omit()

# Scaling the data
toxins_clustered_total_scaled <- scale(toxins_clustered_total)

# For total data
random_sample_total <- toxins_clustered_total_scaled[sample(1:nrow(toxins_clustered_total_scaled), sample_size), ]

# Step 2: Visualize the elbow method using fviz_nbclust (within-cluster sum of squares)
# On-site data
fviz_nbclust(random_sample_total, kmeans, method = "silhouette") +
  ggtitle("Silhouette Method for Total Data")


# Clustering with 2 clusters for on-site
kmeans_total <- kmeans(toxins_clustered_total_scaled, centers = 2)
kmeans_total$centers
kmeans_total$size
kmeans_total$tot.withinss

# Display the ratio of between_SS to total_SS
between_tot_ratio_total <- kmeans_total$betweenss / kmeans_total$totss * 100
cat("Between_SS / Total_SS =", round(between_tot_ratio_total, 1), "%\n")


fviz_cluster(kmeans_total, data = toxins_clustered_total_scaled, 
             geom = "point", ellipse.type = "norm", 
             ggtheme = theme_minimal())


```
## PCA

```{r PCA}

# Perform PCA on on-site scaled data
pca_on_site <- prcomp(toxins_clustered_on_site_scaled, center = TRUE, scale. = TRUE)

# Summary of PCA to see variance explained by each principal component
summary(pca_on_site)

# Visualize the PCA
# Scree plot to show the variance explained by each principal component
fviz_eig(pca_on_site)



# Alternatively, you can plot the contributions of each variable to the first two principal components
fviz_pca_var(pca_on_site, 
             col.var = "contrib", # color based on contributions of variables
             gradient.cols = c("blue", "green", "red"), 
             repel = TRUE) # repel text to avoid overlap


# Perform PCA on off-site scaled data
pca_off_site <- prcomp(toxins_clustered_off_site_scaled, center = TRUE, scale. = TRUE)

# Summary of PCA to see variance explained by each principal component
summary(pca_off_site)

# Visualize the PCA
# Scree plot to show the variance explained by each principal component
fviz_eig(pca_off_site)


# Alternatively, you can plot the contributions of each variable to the first two principal components
fviz_pca_var(pca_off_site, 
             col.var = "contrib", # color based on contributions of variables
             gradient.cols = c("blue", "green", "red"), 
             repel = TRUE) # repel text to avoid overlap


# Perform PCA on off-site scaled data
pca_total <- prcomp(toxins_clustered_total_scaled, center = TRUE, scale. = TRUE)

# Summary of PCA to see variance explained by each principal component
summary(pca_total)

# Visualize the PCA
# Scree plot to show the variance explained by each principal component
fviz_eig(pca_total)


# Alternatively, you can plot the contributions of each variable to the first two principal components
fviz_pca_var(pca_total, 
             col.var = "contrib", # color based on contributions of variables
             gradient.cols = c("blue", "green", "red"), 
             repel = TRUE) # repel text to avoid overlap


# Step 1: Extract the first 2 PCs for on-site and off-site data
pca_scores_on_site <- pca_on_site$x[, 1:2]  # First 2 PCs for On-Site
pca_scores_off_site <- pca_off_site$x[, 1:2]  # First 2 PCs for Off-Site
pca_score_total <- pca_total$x[,1:2]

# Step 2: Combine PCA scores with the original data
pca_on_site <- cbind(toxins_clustered_on_site, pca_scores_on_site)
pca_off_site <- cbind(toxins_clustered_off_site, pca_scores_off_site)
pca_total <- cbind(toxins_clustered_total, pca_score_total)

# Step 3: Scale PCA scores and the original data
pca_on_site_scaled <- scale(pca_on_site[, (ncol(toxins_clustered_on_site) + 1):(ncol(toxins_clustered_on_site) + 2)])  # Scale PCA scores
pca_off_site_scaled <- scale(pca_off_site[, (ncol(toxins_clustered_off_site) + 1):(ncol(toxins_clustered_off_site) + 2)])  # Scale PCA scores
pca_total_scaled <- scale(pca_total[, (ncol(toxins_clustered_total) + 1):(ncol(toxins_clustered_total) + 2)])


# Step 4: Run k-means clustering for On-Site data (assume 6 clusters for demonstration)
k_on_site <- kmeans(pca_on_site[, ncol(pca_on_site)-1:ncol(pca_on_site)], centers = 2, nstart = 25)




# Step 5: Calculate the proportion of variance explained by the clustering
cat("Proportion of variance explained (On-Site):", k_on_site$betweenss / k_on_site$totss, "\n")

# Step 6: Visualize clusters for On-Site data
fviz_cluster(list(data = pca_on_site[, ncol(pca_on_site)-1:ncol(pca_on_site)], cluster = k_on_site$cluster),
             geom = "point",
             ellipse.type = "convex",
             show.clust.cent = TRUE,
             main = "Clusters from PCA (On-Site Data)")

random_sample_on_site_pca <- pca_on_site_scaled[sample(1:nrow(pca_on_site_scaled), sample_size), ]

# For off-site data
random_sample_off_site_pca <- pca_off_site_scaled[sample(1:nrow(pca_off_site_scaled), sample_size), ]

random_sample_total_pca <- pca_total_scaled[sample(1:nrow(pca_total_scaled), sample_size), ]

# Step 2: Visualize the elbow method using fviz_nbclust (within-cluster sum of squares)
# On-site data
fviz_nbclust(random_sample_on_site_pca, kmeans, method = "silhouette") +
  ggtitle("Silhouette Method for On-site Data")

# Off-site data
fviz_nbclust(random_sample_off_site_pca, kmeans, method = "silhouette") +
  ggtitle("Silhouette Method for Off-site Data")


# Step 7: Run k-means clustering for Off-Site data (assume 6 clusters for demonstration)
k_off_site <- kmeans(pca_off_site[, ncol(pca_off_site)-1:ncol(pca_off_site)], centers = 2, nstart = 25)

# Step 8: Calculate the proportion of variance explained by the clustering
cat("Proportion of variance explained (Off-Site):", k_off_site$betweenss / k_off_site$totss, "\n")

# Step 9: Visualize clusters for Off-Site data
fviz_cluster(list(data = pca_off_site[, ncol(pca_off_site)-1:ncol(pca_off_site)], cluster = k_off_site$cluster),
            geom = "point",
             ellipse.type = "convex",
             show.clust.cent = TRUE,
             main = "Clusters from PCA (Off-Site Data)")

# Total data
fviz_nbclust(random_sample_total_pca, kmeans, method = "silhouette") +
  ggtitle("Silhouette Method for Total Data")


# Step 7: Run k-means clustering for Off-Site data (assume 6 clusters for demonstration)
k_total <- kmeans(pca_total[, ncol(pca_total)-1:ncol(pca_total)], centers = 2, nstart = 25)

# Step 8: Calculate the proportion of variance explained by the clustering
cat("Proportion of variance explained (Total):", k_total$betweenss / k_total$totss, "\n")

# Step 9: Visualize clusters for Off-Site data
fviz_cluster(list(data = pca_total[, ncol(pca_total)-1:ncol(pca_total)], cluster = k_total$cluster),
            geom = "point",
             ellipse.type = "convex",
             show.clust.cent = TRUE,
             main = "Clusters from PCA (Total Data)")



```

Totals are very strong predictors. 


## MFA

```{r MFA}

# Step 1: Load necessary libraries
library(FactoMineR)
library(factoextra)

# Step 2: Prepare the data
mfa_toxins <- toxins_2023

# Step 3: Select variables for MFA (replace indices with appropriate column numbers)
MFAData <- toxins_2023[, c(37, 23, 46, 8, 44, 65, 88, 94, 106, 107, 119)]

# Step 4: Convert categorical variables to factors and numerical to numeric
# Adjust column indices based on the dataset
categorical_cols <- c(1, 2, 3, 4, 5)  # Example indices for categorical variables
numerical_cols <- c(6, 7, 8, 9, 10, 11)  # Example indices for numerical variables

MFAData[categorical_cols] <- lapply(MFAData[categorical_cols], as.factor)
MFAData[numerical_cols] <- lapply(MFAData[numerical_cols], as.numeric)

# Step 5: Remove rows with missing values
MFAData <- na.omit(MFAData)

# Step 6: Random sampling if dataset is too large
sample_size <- 1000  # Define the desired sample size
if (nrow(MFAData) > sample_size) {
  set.seed(123)  # Ensure reproducibility
  MFAData <- MFAData[sample(1:nrow(MFAData), sample_size), ]
}

# Step 7: Define groups and types for each variable
group_sizes <- rep(1, ncol(MFAData))  # Each variable is its own group
types <- c(rep("n", length(categorical_cols)), rep("s", length(numerical_cols)))  # Types for each variable

# Step 8: Run MFA
MFA1 <- MFA(
  MFAData,
  group = group_sizes,  # Each variable treated as a separate group
  type = types,         # Specify type for each variable
  name.group = colnames(MFAData),  # Use column names for group names
  graph = FALSE         # Do not automatically plot graphs
)

# Step 9: Visualizations

# Scree plot: variance explained by dimensions
fviz_screeplot(MFA1, addlabels = TRUE, ylim = c(0, 50))

# Variable contributions to the dimensions
fviz_mfa_var(MFA1,
             repel = TRUE,  # Avoid label overlap
             col.var = "cos2",  # Color by quality of representation (cos2 indicates the quality)
             gradient.cols = c("blue", "green", "red"))

# Individuals (data points) representation
fviz_mfa_ind(MFA1, 
             repel = TRUE,  # Avoid label overlap
             geom = "point", 
             col.ind = "cos2",  # Color by quality of representation (cos2 indicates the quality)
             gradient.cols = c("blue", "green", "red"))



# Variable contributions to the dimensions (by group)
fviz_mfa_var(mfa_result, "group",
             repel = TRUE,  # Avoid label overlap
             col.var = "cos2",  # Color by quality of representation (cos2 indicates the quality)
             gradient.cols = c("blue", "green", "red"))

fviz_mfa_var(mfa_result, 
             choice = "quanti.var",  # For quantitative variables
             repel = TRUE,           # Avoid label overlap
             col.var = "cos2",       # Color by quality of representation (cos2 indicates the quality)
             gradient.cols = c("blue", "green", "red"))

fviz_mfa_var(mfa_result, 
             choice = "quali.var",  # For categorical variables
             repel = TRUE,
             col.var = "cos2",
             gradient.cols = c("blue", "green", "red"))


fviz_mfa_var(mfa_result, 
             choice = "quali.var",       # Focus on categorical variables
             repel = TRUE,              # Avoid label overlap
             col.var = "cos2",          # Color by quality of representation
             gradient.cols = c("blue", "green", "red"),
             axes = c(1, 2))            # Specify dimensions to plot




# Contributions of qualitative variables to Dimension 1
fviz_contrib(mfa_result, element = "quali.var", axes = 1, top = 10)

# Contributions of qualitative variables to Dimension 2
fviz_contrib(mfa_result, element = "quali.var", axes = 2, top = 10)





```







